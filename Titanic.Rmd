---
title: 'Titanic: Machine Learning from Disaster'
author: "Omer Shechter"
date: "March 2019"
output:
  html_document:
    toc: true
    toccolor: 'blue'
    header-includes:
    - \usepackage {hyperref}
    - \hypersetup {colorlinks = true, linkcolor = blue, urlcolor = blue}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE )
library(ggplot2)
library(dplyr)
library(tidyverse)
library(knitr)
library(kableExtra)
library(data.table)
library(scales)
library(tidytext)
library(quanteda)
library(data.table)
library(GGally)
library(varhandle)
library(gridExtra)
library(stringr)
library(caret)
library(randomForest)
library(rpart)
library(leaps)
library(fastDummies)
library(glmnet)
library(boot)
```

# Titanic: Machine Learning from Disaster

R markdown for providing my approach to the Titanic
Competition in Kaggle 
This kernel includes data loading cleaning and some exploratory work
it also contains basic modeling 

# Exploratory Data 

### Normalize function Helper

A simple normalize function, which normalizes
continuous data to values between 0 and 1 
some machine learning models work better with normalize data 
```{r}

##########################
#Function normalize      #
#Input  X  vector        #
#Return Normlize vector  #
#                        #
#                        #
#########################



normalize <- function(x) {
    return ((x - min(x,na.rm =TRUE)) / (max(x,na.rm =TRUE) - min(x,na.rm =TRUE)))
  }
```


## Loading the train and test sets 
```{r date load}
setwd("E:/Elements/kaggle/Kaggle_Titanic")
#setwd("C:/Users/cbs/Documents/R/Kaggle.Titanic")
train<-read.csv("train.csv")
test<-read.csv("test.csv")
#Create Raw train, test and combined data
#Combined data will be used to do common preprocessing  (test and train)
#Though we will be careful not to allow a leak of a data 
#from train to test data 
Rawtrain<-train
Rawtest<-test
# To combine the train and test - 
#create dummy Survived column (and then remove it)
Rawtest['Survived']<-0
RawData<-rbind(train,Rawtest)
Rawtest<-subset(Rawtest,select = -Survived)

```

First, Let's review the data.
```{r train data}
#Create a table of the first ten observations
kable(head(Rawtrain)) %>%
  kable_styling(c("striped", "bordered")) %>%
  add_indent(c(1, 3, 5))
```

The label data, what we need to predict is the Survival column 
0 - No 
1-  Yes 
This set is a classification set.

One of the first steps is to take a look if the labels are not skew and we have a balance classification. 


```{r bar plot survivved }

# Using the ggplot Package                         
# Plotting a Bar plot of the Survivles Vs. Death   
p<-ggplot(data=Rawtrain,aes(x=as.factor(Survived)))+ 
  geom_bar(aes(y = (..count..)) , fill = c('red','green'))
p<-p+xlab("Survived: 0 - No , 1 - Yes") + ylab("Count")
p<-p+labs(title="Survives Versus No Survivors counts ")
p<-p+geom_text(aes(y = (..count..),label =   ifelse((..count..)==0,"",
  scales::percent((..count..)/sum(..count..)))), stat="count",colour="black") 
p
```

There is some skew as the number of Survival is smaller (ratio of 60%:40%)
It is not a large skew if we use cross-validation techniques it probably not a big issue 

## Missing Data 

Let's review how much data we are missing. 
Note: Some of the string variables have empty data and not null 
so first, we replace Empty data by NA 
```{r}

#Some of the missing data is NA, and some (mainly strings) is empty data 
#convert empty strings to NA 
Rawtrain<-Rawtrain %>% 
       mutate(Cabin = if_else(as.character(Cabin)=="", NA_character_ ,as.character(Cabin)))

Rawtrain<-Rawtrain %>% 
       mutate(Ticket = if_else(as.character(Ticket)=="", NA_character_ ,as.character(Ticket)))

Rawtrain<-Rawtrain %>% 
       mutate(Embarked = if_else(as.character(Embarked)=="", NA_character_ ,as.character(Embarked)))

Rawtest<-Rawtest %>% 
       mutate(Cabin = if_else(as.character(Cabin)=="", NA_character_ ,as.character(Cabin)))

Rawtest<-Rawtest %>% 
       mutate(Ticket = if_else(as.character(Ticket)=="", NA_character_ ,as.character(Ticket)))

Rawtest<-Rawtest %>% 
       mutate(Embarked = if_else(as.character(Embarked)=="", NA_character_ ,as.character(Embarked)))


```


```{r}
#Using the Inspect package show all missing items  
inspect.na(Rawtrain, barplot=TRUE)
inspect.na(Rawtest, barplot=TRUE)
```

Age and Cabin has a relatively high amount of missing data.


##Pclass 
Pclass will be used as  a Factor or Categorical variable 

```{r}
#plot Pcalss Versus Death  Survived 
theme_update(plot.title = element_text(hjust = 0.5))
p<-ggplot(Rawtrain, aes((y =..count..),x=Pclass)) + 
  geom_bar(aes(fill = as.factor(Survived)), position = "dodge")
p<-p+xlab("Pclass") + ylab("Count")
p<-p+scale_fill_manual(name="Survived/Death  ",values=c("red", "green"),
                       labels=c("Death", "Survived"))
p<-p+labs(title=" Bar Plot Pclass -- Survived ")
p
```
There are three class types - 1, 2 and 3. 
It Seems that in Class 3 you have less chance to survive 
While in Class 1 you had a higher chance to survive 
In Class 2 the odd are Equal 
Convert the Pclass to Factor variable

```{r}

#Convert to a factor
Rawtest$Pclass<-as.factor(Rawtest$Pclass)
Rawtrain$Pclass<-as.factor(Rawtrain$Pclass)

```
## Sex

Plot Sex Versus Survived Death 
```{r}

#Plot Sex Versus Survived Death 
p<-ggplot(data=Rawtrain,aes(x=as.factor(Survived),
                            fill=Sex))+geom_bar()
p<-p+scale_fill_manual("legend", values =
                         c("male" = "blue", "female" = "red"))
p<-p+xlab("Survived: 0 - No, 1 - Yes") + ylab("Count")
p<-p+labs(title="Survives Vs. Death Based on Sex ")
p<-p+geom_text(aes(label=..count..),
               stat="count",position=position_stack(0.5))
p
```

Table of Sex Counts 
```{r}
kable(table(Rawtrain$Sex),col.names = c("Sex","Frequency")) %>%
  kable_styling("striped", full_width = F) 
  
```
Checking the Correlation 
To check Correlation, we create a Categorical variable 
1 - Female
0 - Sex 
```{r}
#Using GGpairs draw correlation graphs
Rawtrain<-mutate(Rawtrain,Sexb=ifelse(Sex=="female",1,0))
Rawtest<-mutate(Rawtest,Sexb=ifelse(Sex=="female",1,0))
ggpairs(subset(Rawtrain,select=c("Survived", "Sexb")))
```

Conclusion :
1. No Missing data or NA 
2. There is some correlation between Sex and Survival 
2. Sex looks like a good predictor/Feature to use 

## Age 
Plot Age Versus Survived Death 
```{r}
#Plot Age Versus Survived Death 
p<-ggplot(Rawtrain,aes(x=Age,group=as.factor(Survived),
                       fill=as.factor(Survived)))+
  geom_density(alpha = 0.5)
p<-p+scale_fill_manual("legend",labels = c("Dead", "Survived"),
                       values = c("red","green"))

p
```
Later we will use the Data from the Sex and names to complete the missing data. 
Look for outliers and another way to look at the relation between Age and survivals.

```{r}
#Boxplot Age - Versus Survived or Death
p<-ggplot(Rawtrain, aes(x=as.factor(Survived),y=Age,
                        color = as.factor(Survived))) +   geom_boxplot()
p<-p+scale_color_manual(values=c("red", "green"))
p<-p+xlab("Survived: 0 - No , 1 - Yes") + ylab("Age - Years")
p<-p+labs(title=" Boxplot Of Survivals/Death -- Age")
p
```
We can see that Age as a continuous feature/Predictor there are points 
it is a good predictor and some that it doesn't 

## (Passenger) Name
In this part, we are doing some simple text analytics 
Let's try to understand what  type of word the naming 
feature can provide 
The step we will take care 
1.Build a corpus
2. Tokenize (converting to tokens, words in this case ) 
   Removing numbers, symbols  separators, punctuation and some 
   another standard cleaning (though it is probably less needed here )
3.Create Uni Grahm 
4.Sort according to count (Frequency )
```{r}
#Create Corpus
corp <- corpus(as.character(RawData$Name))
#Tokenize
Text.Sentences <- tokens(
  x = tolower(corp),
  remove_punct = TRUE,
  remove_twitter = TRUE,
  remove_numbers = TRUE,
  remove_hyphens = TRUE,
  remove_symbols = TRUE,
  remove_separators = TRUE,
  remove_url = TRUE)

##############################################
# Create Uni Gram                            #
#                                            #
##############################################
uni_DFM <- dfm(Text.Sentences)
#Trim to Words with Priority higher than 2

#Calculate the Col Sum 
sums_U <- colSums(uni_DFM)

#PAck in Data table 
uni_words <- data.table(word_1 = names(sums_U), count = sums_U)

#Sort 
setorder(uni_words,-count)
#Print Table
kable(head(uni_words,15)) %>%
  kable_styling("striped", full_width = F) %>%
  add_indent(c(1, 3, 5))

```

The most interesting results are 
Mr, Miss, Mrs and Master (Master in the old days is a boy under 18)
We can use this information for two purpose 

1. There are 177 passengers that their age is missing, we can use this data to have a better technique to complete missing data (using mean according to the titles)
2. We can use the information to create a feature  married or not a married woman

Based on the results build a new column 
Mr, Miss, Mrs or Master 

```{r}


#Use the Tokens Vector to build a title column
Text<-sapply(Text.Sentences,as.character)
regex <- 
chkmr<-grepl(paste0(sprintf("(?=.*%s)", "mr"), collapse = ''), Text, perl = TRUE)
chkmiss<-grepl(paste0(sprintf("(?=.*%s)", "miss"), collapse = ''), Text, perl = TRUE)
chkmrs<-grepl(paste0(sprintf("(?=.*%s)", "mrs"), collapse = ''), Text, perl = TRUE)
chkmaster<-grepl(paste0(sprintf("(?=.*%s)", "master"), collapse = ''), Text, perl = TRUE)

RawData<-RawData%>%mutate(Title=ifelse(chkmrs,"Mrs",ifelse(chkmiss,"Miss",ifelse(chkmr,"Mr.",
                                                                                  ifelse(chkmaster,"Master","None")))))

```

Let's look at a summary after populating the title.

```{r}
kable(table(RawData$Title),col.names = c("Title","Frequency")) %>%
  kable_styling("striped", full_width = F) 
```
Let's look on the None title items 
```{r}
kable(filter(RawData,Title =="None"))%>%
  kable_styling(c("striped", "bordered"))
```

It looks like we should add the following 
1. Dr.  - For Doctors 
2. Rev  - 
3. Army - Majo. Col. Capt.
4. Dona and Don will be treated as Mrs and Mr.

```{r}

chkdr<-grepl(paste0(sprintf("(?=.*%s)", "dr"), collapse = ''), Text, perl = TRUE)
chkrev<-grepl(paste0(sprintf("(?=.*%s)", "rev"), collapse = ''), Text, perl = TRUE)
chkArmy1<-grepl(paste0(sprintf("(?=.*%s)", "major"), collapse = ''), Text, perl = TRUE)
chkArmy2<-grepl(paste0(sprintf("(?=.*%s)", "col"), collapse = ''), Text, perl = TRUE)
chkArmy3<-grepl(paste0(sprintf("(?=.*%s)", "capt"), collapse = ''), Text, perl = TRUE)

RawData<-RawData%>%
  mutate(Title2=ifelse(chkdr ,"Dr.",ifelse(chkrev,"Rev.",ifelse(chkArmy1,"Army",ifelse(chkArmy2,"Army",                                                                                   ifelse(chkArmy3,"Army","None")))))) 

chkdon<-grepl(paste0(sprintf("(?=.*%s)", "don"), collapse = ''), Text, perl = TRUE)
chkdone<-grepl(paste0(sprintf("(?=.*%s)", "dona"), collapse = ''), Text, perl = TRUE)

RawData<-RawData%>%
  mutate(Title3=ifelse(chkdon ,"Mr.",ifelse(chkdone,"Mrs" ,"None")))                                              

```

Merging the three  titles 

```{r}
RawData$Title[RawData$Title == "None"] <- RawData$Title2[RawData$Title == "None"]
RawData$Title[RawData$Title == "None"] <- RawData$Title3[RawData$Title == "None"]
RawData <- subset(RawData, select = -c(Title2,Title3))
Rawtrain[,"Title"]<-RawData[1:nrow(Rawtrain),"Title"]

test.index<-(nrow(Rawtrain)+1):(nrow(Rawtrain)+nrow(Rawtest))
Rawtest[,"Title"]<-RawData[test.index,]$Title
```

Plot a Survived Death boxplot based on the titles 
```{r}
#Plot a Survived Death boxplot based on the titles 
p<-ggplot(Rawtrain, aes((y =..count..),x=Title)) +
  geom_bar(aes(fill = as.factor(Survived)), position = "dodge")
p<-p+xlab("Title") + ylab("Count")
p<-p+scale_fill_manual(name="Survived/Death  ",
                       values=c("red", "green"), labels=c("Death", "Survived"))
p<-p+labs(title=" Bar Plot Title -- Survived ")
p
```


## Handling Title missing data using Age And Sex 

First, let's see with current data what 
is the data about Age per Title. 

```{r}
p<-ggplot(Rawtrain, aes(x=as.factor(Title),y=Age,color = as.factor(Title))) +   geom_boxplot()
p<-p+xlab("Title") + ylab("Age - Years")
p<-p+labs(title=" Boxplot Of Title -- Age ")
p
```

Calculate Mean Median and SD  for Age per Title 
### Train
```{r}
TitlesOptions<-c("Mr.","Miss","Mrs","Master","Dr.","Army","Rev.")
for (i in 1:length(TitlesOptions))
{
  df<-subset(Rawtrain,(Title==TitlesOptions[i]))
  Mean<-mean(df$Age,na.rm=TRUE) 
  Median<-median(df$Age,na.rm=TRUE)
  Sdv<-sd(df$Age,na.rm=TRUE)
  
  n = dim((subset(Rawtrain,Title==TitlesOptions[i] & !is.na(Age))))[1]
  Esdv <- sqrt(Sdv^2/n)
  
  if (i==1)
    DFAgeStat<-data.frame("Title" = TitlesOptions[i],"Mean" = Mean , "Median" = Median , "Sdv" = Sdv , "Esdv" = Esdv  )
  else
  {
    DF<-data.frame("Title" = TitlesOptions[i],"Mean" = Mean , "Median" = Median , "Sdv" = Sdv , "Esdv" = Esdv )
    DFAgeStat<-rbind(DFAgeStat,DF)
  }

}

#Show the statisticl results
kable((DFAgeStat)) %>%
  kable_styling("striped", full_width = F) 
```



```{r}

SexOptions<-c("male","female")
for (i in 1:length(SexOptions))
{
    df<-subset(Rawtrain,(Sex==SexOptions[i]))
    Mean<-mean(df$Age,na.rm=TRUE) 
    Median<-median(df$Age,na.rm=TRUE)
    
   
    
    Sdv<-sd(df$Age,na.rm=TRUE)
    if (i==1)
      DFSexStat<-data.frame("Sex" = SexOptions[i],"Mean" = Mean , "Median" = Median , "Sdv" = Sdv )
    else
    {
      DF<-data.frame("Sex" = SexOptions[i],"Mean" = Mean , "Median" = Median , "Sdv" = Sdv )
      DFSexStat<-rbind(DFSexStat,DF)
    }
}


kable((DFSexStat)) %>%
  kable_styling("striped", full_width = F) 

DFAgeStat<-setDT(DFAgeStat)
setkey(DFAgeStat,Title,Mean,Median,Sdv)
```

The logic will be: 
If we have Title and missing age we will use the mean title to complete 
If we have the age data  but no Title data  we can add the Title (based on age and sex)
if we only have sex, we will use it to evaluate the age and title 

Preparing three  approaches for later user 
1. Use the mean 
2. Use the median 
3. Use Random normal distribution variable

Since this is like building a small model, we will use them 
Mean Median and the Random variables that is computes using the train data 
and complete the data using the model for both the test and the train sets 

## Complete Missing Age 

```{r}
#Handle cases where Age is missing, but we have the Title data 
# The 

#Loop creating the three options described above 
TitlesOptions<-c("Mr.","Miss","Mrs","Master","Dr.","Army","Rev.")
Rawtrain<-mutate(Rawtrain,AgeMean=Age)
Rawtrain<-mutate(Rawtrain,AgeMedian=Age)
Rawtrain<-mutate(Rawtrain,AgeNormal=Age)
set.seed(444)
for (i in 1:length(TitlesOptions))
{
  #Mean
  Rawtrain$AgeMean[is.na(Rawtrain$Age) & Rawtrain$Title == TitlesOptions[i]]<- DFAgeStat[.(TitlesOptions[i])]$Mean
  #Median
  Rawtrain$AgeMedian[is.na(Rawtrain$Age) & Rawtrain$Title == TitlesOptions[i]]<- DFAgeStat[.(TitlesOptions[i])]$Median
  #Normal Distrbution variable based on the Mean and SD 
  
  #Calculate the number of missing items 
  n<-dim(subset(Rawtrain,is.na(Rawtrain$Age) & Rawtrain$Title == TitlesOptions[i]))[1]
  #Create a Normal Random Variable with Mean  and SD^2/n  and sample according to n
  Rawtrain$AgeNormal[is.na(Rawtrain$Age) & Rawtrain$Title == TitlesOptions[i]]<-
    sample(rnorm(10000,DFAgeStat[.(TitlesOptions[i])]$Mean,DFAgeStat[.(TitlesOptions[i])]$Esdv),n)   
  
}

#Repeat the same process over the test set 
Rawtest<-mutate(Rawtest,AgeMean=Age)
Rawtest<-mutate(Rawtest,AgeMedian=Age)
Rawtest<-mutate(Rawtest,AgeNormal=Age)
set.seed(444)
for (i in 1:length(TitlesOptions))
{
  #Mean
  Rawtest$AgeMean[is.na(Rawtest$Age) & Rawtest$Title == TitlesOptions[i]]<- DFAgeStat[.(TitlesOptions[i])]$Mean
  #Median
  Rawtest$AgeMedian[is.na(Rawtest$Age) & Rawtest$Title == TitlesOptions[i]]<- DFAgeStat[.(TitlesOptions[i])]$Median
  #Normal Distrbution variable based on the Mean and SD 
  
  #Calculate the number of missing items 
  n<-dim(subset(Rawtest,is.na(Rawtest$Age) & Rawtest$Title == TitlesOptions[i]))[1]
  #Create a Normal Random Variable with Mean  and SD^2/n  and sample according to n
  Rawtest$AgeNormal[is.na(Rawtest$Age) & Rawtest$Title == TitlesOptions[i]]<-
    sample(rnorm(10000,DFAgeStat[.(TitlesOptions[i])]$Mean,DFAgeStat[.(TitlesOptions[i])]$Esdv),n)   
  
} 


  

```

Finaly let's  compare the 4 new Age tables to verify the results (Train set)

### Age Versus Titles - Train 
```{r fig.width=14, fig.height=14}
#Plot the Original Age column (this time without the NA values)
p1<-ggplot(subset(Rawtrain,!is.na(Age)), aes(x=as.factor(Title),
                          y=Age,color = as.factor(Title))) +   geom_boxplot()
p1<-p1+xlab("Title") + ylab("Age - Years")
p1<-p1+labs(title=" Boxplot Of Title -- Age ")
p1<-p1+theme(axis.title.x = element_text(size = rel(1.2)),
             axis.title.y = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
         axis.text.x.top =  element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)))

p1<-p1+theme(axis.text.x = element_text(size=12 ))
p1<-p1+theme(axis.text.y = element_text(size=12 ))
p1<-p1+ labs(col="Title")                          


p2<-ggplot(Rawtrain, aes(x=as.factor(Title),y=AgeMean,color = as.factor(Title))) +   geom_boxplot()
p2<-p2+xlab("Title") + ylab("Age  - Years")
p2<-p2+labs(title=" Boxplot Of Title -- Age Missing Data Method: - Mean  ")
p2<-p2+theme(axis.title.x = element_text(size = rel(1.2)),
             axis.title.y = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
         axis.text.x.top =  element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)))

p2<-p2+theme(axis.text.x = element_text(size=12 ))
p2<-p2+theme(axis.text.y = element_text(size=12 ))
p2<-p2+ labs(col="Title")  


p3<-ggplot(Rawtrain, aes(x=as.factor(Title),y=AgeMedian,color = as.factor(Title))) +   geom_boxplot()
p3<-p3+xlab("Title") + ylab("Age  - Years")
p3<-p3+labs(title=" Boxplot Of Title -- Age Missing Data Method: - Median  ")
p3<-p3+theme(axis.title.x = element_text(size = rel(1.2)),
             axis.title.y = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
         axis.text.x.top =  element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)))

p3<-p3+theme(axis.text.x = element_text(size=12 ))
p3<-p3+theme(axis.text.y = element_text(size=12 ))
p3<-p3+ labs(col="Title")  

p4<-ggplot(Rawtrain, aes(x=as.factor(Title),y=AgeNormal,color = as.factor(Title))) +   geom_boxplot()
p4<-p4+xlab("Title") + ylab("Age  - Years")
p4<-p4+labs(title=" Boxplot Of Title -- Age Missing Data Method: - Normal Random Variable  ")
p4<-p4+theme(axis.title.x = element_text(size = rel(1.2)),
             axis.title.y = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
         axis.text.x.top =  element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)))

p4<-p4+theme(axis.text.x = element_text(size=12 ))
p4<-p4+theme(axis.text.y = element_text(size=12 ))
p4<-p4+ labs(col="Title")  




grid.arrange(p1,p2,p3,p4,nrow =4)


```


### Age Versus Titles - Test 
Creating boxplot of Age versus titles 
1.Original plot (without the NA)
2.With the method of replacing NA by mean 
3. With the technique of replacing Na by median 
4. With the approach of replacing NA by Random variable 
```{r fig.width=14, fig.height=14}
#Plot the Original Age column (this time without the NA values)
p1<-ggplot(subset(Rawtest,!is.na(Age)), aes(x=as.factor(Title),
                          y=Age,color = as.factor(Title))) +  
  geom_boxplot()
p1<-p1+xlab("Title") + ylab("Age - Years")
p1<-p1+labs(title=" Boxplot Of Title -- Age ")
p1<-p1+theme(axis.title.x = element_text(size = rel(1.2)),
             axis.title.y = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
         axis.text.x.top =  element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)))

p1<-p1+theme(axis.text.x = element_text(size=12 ))
p1<-p1+theme(axis.text.y = element_text(size=12 ))
p1<-p1+ labs(col="Title")                          


#Plot the Age column (this time with Age mean instead of  the NA values)
p2<-ggplot(Rawtest, aes(x=as.factor(Title),
                        y=AgeMean,color = as.factor(Title))) +   geom_boxplot()
p2<-p2+xlab("Title") + ylab("Age  - Years")
p2<-p2+labs(title=" Boxplot Of Title -- Age Missing Data Method: - Mean  ")
p2<-p2+theme(axis.title.x = element_text(size = rel(1.2)),
             axis.title.y = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
         axis.text.x.top =  element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)))

p2<-p2+theme(axis.text.x = element_text(size=12 ))
p2<-p2+theme(axis.text.y = element_text(size=12 ))
p2<-p2+ labs(col="Title")  

#Plot the Age column (this time with Age median instead of  the NA values)
p3<-ggplot(Rawtest, aes(x=as.factor(Title),
                        y=AgeMedian,color = as.factor(Title))) +   geom_boxplot()
p3<-p3+xlab("Title") + ylab("Age  - Years")
p3<-p3+labs(title=" Boxplot Of Title -- Age Missing Data Method: - Median  ")
p3<-p3+theme(axis.title.x = element_text(size = rel(1.2)),
             axis.title.y = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
         axis.text.x.top =  element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)))

p3<-p3+theme(axis.text.x = element_text(size=12 ))
p3<-p3+theme(axis.text.y = element_text(size=12 ))
p3<-p3+ labs(col="Title")  

#Plot the Age column (this time with a normal random variable instead of  the NA values)
p4<-ggplot(Rawtest, aes(x=as.factor(Title),
                        y=AgeNormal,color = as.factor(Title))) +   geom_boxplot()
p4<-p4+xlab("Title") + ylab("Age  - Years")
p4<-p4+labs(title=" Boxplot Of Title -- Age Missing Data Method: - Normal Random Variable  ")
p4<-p4+theme(axis.title.x = element_text(size = rel(1.2)),
             axis.title.y = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
         axis.text.x.top =  element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)))

p4<-p4+theme(axis.text.x = element_text(size=12 ))
p4<-p4+theme(axis.text.y = element_text(size=12 ))
p4<-p4+ labs(col="Title")  


grid.arrange(p1,p2,p3,p4,nrow =4)


```
As we can see in all methods, there is no drastic change 
(There are  more outlier, but this is expected as we had more samples)

### Complete Missing Titles 
We can complete the missing titles  data based on Age and Sex 
We will choose either Mr., Mrs. Miss or Master  

```{r}
#Subset the missing titles 
res<-Rawtrain[Rawtrain$Title=="None",]

#Complate based on the following
#Male < 18 - Master
#Female <28 - Miss
#Female >=8 Mrs.
#Male >18 Mr.
Rawtrain[Rawtrain$Title=="None",]$Title<-
  ifelse(res$Age<18 & res$Sex=="male","Master",ifelse(res$Age<28 &   
                        res$Sex=="female","Miss",
                        ifelse(res$Sex=="female" & res$Age>=28,"Mrs","Mr.")))

Rawtest[Rawtest$Title=="None",]

#Convert to Factors 
Rawtrain$Title<-as.factor(Rawtrain$Title)
Rawtest$Title<-as.factor(Rawtest$Title)
```

No missing data for the Test set 

## SibSp & Parch

Sibsp - Number of siblings/spouses aboard the Titanic
Parch - Number of parents/children aboard the Titanic

Plot Sibsp Versus Survived Death 
```{r}
#Plot Sibsp Versus Survived Death 
p<-ggplot(Rawtrain,aes(x=as.factor(SibSp),
                       group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_bar()
p<-p+labs(title=" Bar Plot of Sibsp Vs. Survived  ")
p<-p+scale_fill_manual("legend",
                       labels = c("Dead", "Survived"), values = c("red","green"))
p<-p+xlab("Sibsp ") + ylab("Count")
p
```


Plot Parch Versus Survived Death 
```{r}
#Plot Parch Versus Survived Death 
p<-ggplot(Rawtrain,aes(x=as.factor(Parch),
                       group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_bar()
p<-p+labs(title=" Bar Plot of Parch Vs. Survived ")
p<-p+scale_fill_manual("legend",labels = c("Dead", "Survived"),
                       values = c("red","green"))
p<-p+xlab("Parch ") + ylab("Count")
p
```


Let's try to build some categorical parameters based on these two variables 
Ans see the impact on Survived/Death

First - Is the passengers alone 

```{r}
Rawtrain<-Rawtrain%>%mutate(Isalone=ifelse((SibSp+Parch) > 0,0,1))
Rawtest<-Rawtest%>%mutate(Isalone=ifelse((SibSp+Parch) > 0,0,1))

p<-ggplot(Rawtrain,aes(x=as.factor(Isalone),
                       group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_bar()
p<-p+labs(title=" Bar Plot of Isalone  Vs. Survived ")
p<-p+xlab("Is Alone 1 - Yes  0 - No ") + ylab("Count")
p<-p+scale_fill_manual("legend",labels = c("Dead", "Survived"), values = c("red","green"))
p

```

Create a column with the total number of people in the group

```{r}
Rawtrain<-Rawtrain%>%mutate(GroupNo=SibSp+Parch)
Rawtest<-Rawtest%>%mutate(GroupNo=SibSp+Parch)
p<-ggplot(Rawtrain,aes(x=as.factor(GroupNo),
                       group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_bar()
p<-p+labs(title=" Bar Plot of Group size  Vs. Survived  ")
p<-p+scale_fill_manual("legend",labels = c("Dead", "Survived"), values = c("red","green"))
p

```


It looks like a group of 4 and above has less chance to survive. 

```{r}
#Rawtrain<-Rawtrain%>%mutate(IsLArgeGroup=ifelse(SibSp+Parch>=4,1,0))
#Rawtest<-Rawtest%>%mutate(IsLArgeGroup=ifelse(SibSp+Parch>=4,1,0))

```


## Ticket
Ticket observations contain  a set of characters
(or nothing)  and then numbers 
The first step clean the ticket 
observations and create a column with only 
the character set and a separate column for the number
```{r}

#Remove all the digits 
#(Since the characters may have numbers also we remove when there is an occurrence of three or more )
RawData<-RawData%>%
mutate(TicketChar = gsub("[0-9]{3,}","",Ticket))

#Mark all empty Ticket Char by U 
RawData$TicketChar<-ifelse(RawData$TicketChar=="","U",RawData$TicketChar)

#Create anothher colomn with the numbers
RawData<-RawData%>%
mutate(TicketNumbers = strtoi(str_extract(Ticket,"[0-9]{3,}")))


#In the majority of the data the above
#condition (3 digits or above in a row )
#is Enough, There are few other cases
#where there are only characters, or there is one digit 
#Handle these cases 
#Extract the Digits and place them in the TicketNumbers
res<-as.numeric((RawData%>%
                   filter(grepl("\\. [0-9]{1}$",Ticket)))$Ticket%>%str_extract_all(" [0-9]{1}$"))
RawData[grep("\\. [0-9]{1}$",RawData$Ticket),]$TicketNumbers<-res
#make sure that all values are numerics 
RawData$TicketNumbers<-
  as.numeric(RawData$TicketNumbers)

#Set number 100 to the Ticketnumbers 
RawData[is.na(RawData$TicketNumbers),]$TicketNumbers<-
  as.integer(mean(RawData$TicketNumbers,na.rm = TRUE))


#Create A normlize TicketNumbers 
RawData<-RawData%>%mutate(TicketNumbers_Nor =normalize(TicketNumbers))

#Extract the Character part to TicketChar
res<-((RawData%>%filter(grepl("\\. [0-9]{1}$",Ticket)))$Ticket%>%str_extract_all("[^0-9 ]{1,}"))
RawData[grep("\\. [0-9]{1}$",RawData$Ticket),]$TicketChar<-res
RawData$TicketChar<-as.character(RawData$TicketChar)

#Handle the cases that there are no digits 
res<-as.character(subset(RawData,grepl("^[A-Za-z]+$",Ticket,perl=T))$Ticket)
RawData[grep("^[A-Za-z]+$",RawData$Ticket,perl=T),]$TicketChar<-res

#Remove dots  spaces and / from the Ticket chars
RawData$TicketChar<-str_replace_all(RawData$TicketChar,"[.]","")
RawData$TicketChar<-str_replace_all(RawData$TicketChar,"[ ]{1,}","")
RawData$TicketChar<-str_replace_all(RawData$TicketChar,"[///]{1,}","")

#Copy the Ticket new columns to the train and test sets
Rawtrain[,c("TicketChar","TicketNumbers","TicketNumbers_Nor")]<-
  RawData[1:nrow(Rawtrain),c("TicketChar","TicketNumbers","TicketNumbers_Nor")]
test.index<-(nrow(Rawtrain)+1):(nrow(Rawtrain)+nrow(Rawtest))
Rawtest[,c("TicketChar","TicketNumbers","TicketNumbers_Nor")]<-
  RawData[test.index,c("TicketChar","TicketNumbers","TicketNumbers_Nor")]
```

We need to verify that in the Test set there are no 
Ticket characters which are missing in the train set 
if this is the case we replace them with U 

```{r}
#Create a Match matrix 
TrainTicketchr<-sort(unique(Rawtrain$TicketChar))
TestTicketchr<-sort(unique(Rawtest$TicketChar))

MatchTicketChar<-match(TestTicketchr,TrainTicketchr)
#Checkk all NA in the test set 
Missing_Items<-TestTicketchr[which(is.na(MatchTicketChar))]

#Check how many items we are missing 
count<-0
for(i in 1:length(Missing_Items))
{
  count<-count + dim(Rawtest[Rawtest$TicketChar==Missing_Items[i],])[1]
  #Change the Missing Test items to U
  Rawtest[Rawtest$TicketChar==Missing_Items[i],]$TicketChar<-"U"
  
}
cat("Missing items",count)


#Create common factor levels 
df<-rbind(Rawtrain[,-2],Rawtest)
df$TicketChar<-as.factor(df$TicketChar)

Rawtrain$TicketChar<-df[1:nrow(Rawtrain),]$TicketChar
test.index<-(nrow(Rawtrain)+1):(nrow(Rawtrain)+nrow(Rawtest))
Rawtest$TicketChar<-df[test.index,]$TicketChar



```



```{r fig.width=14, fig.height=10}
#Plot a barplot of the ticket prefix versus Survived or Death (Omit the Unspecified - U)
p<-ggplot(subset(Rawtrain,TicketChar!="U"),
          aes(x=as.factor(TicketChar),
              group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_bar()
p<-p+labs(title=" Bar Plot of TicketChar (Survived Vs. Death) ")
p<-p+theme(axis.text.x=element_text(angle=45, hjust=1))
p<-p+xlab("Ticket Characters")
p<-p+scale_fill_manual("legend",labels = c("Dead", "Survived"), values = c("red","green"))
p
```

## Fare

The fare is a continues parameter
There is one observation  missing
Replace the missing value by the mean
```{r}
if (sum(is.na(RawData$Fare))>0)
  RawData[is.na(RawData$Fare),]$Fare<-mean(RawData$Fare,na.rm = TRUE)
Rawtrain[,c("Fare")]<-RawData[1:nrow(Rawtrain),c("Fare")]
test.index<-(nrow(Rawtrain)+1):(nrow(Rawtrain)+nrow(Rawtest))
Rawtest[,c("Fare")]<-RawData[test.index,c("Fare")]


```
plot the Fare Versus Survived or Death

```{r}
#plot the Fare Versus Survived or Death 
p<-ggplot(Rawtrain,aes(x=Fare,
                       group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_density(alpha = 0.5)
p<-p+labs(title=" Density Plot of Fare (Survived Vs. Death) ")
p<-p+scale_fill_manual("legend",
                       labels = c("Dead", "Survived"), values = c("red","green"))
p
```

Split Fare to subarea 
```{r}
p<-subset(Rawtrain,Fare<50)%>%
  ggplot(aes(x=Fare,group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_density(alpha = 0.5)
p<-p+labs(title=" Density Plot of Fare (Survived Vs. Death) Fare < 50")
p<-p+scale_fill_manual("legend",
                       labels = c("Dead", "Survived"), values = c("red","green"))
p
  
```



```{r}
p<-subset(Rawtrain,Fare>50 & Fare<100)%>%
  ggplot(aes(x=Fare,group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_density(alpha = 0.5)
p<-p+labs(title=" Density Plot of Fare (Survived Vs. Death) Fare Between 50 and 100")
p<-p+scale_fill_manual("legend",labels = c("Dead", "Survived"), values = c("red","green"))
p
```


```{r}
p<-subset(Rawtrain,Fare>100)%>%
  ggplot(aes(x=Fare,group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_density(alpha = 0.5)
p<-p+labs(title=" Density Plot of Fare (Survived Vs. Death) Fare Above 100")
p<-p+scale_fill_manual("legend",labels = c("Dead", "Survived"), values = c("red","green"))
p
```



## Embarked

Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)

```{r}
#plot Embarked Versus Death Survived 
p<-ggplot(Rawtrain, aes((y =..count..),x=Embarked)) + 
  geom_bar(aes(fill = as.factor(Survived)), position = "dodge")
p<-p+xlab("Embarked") + ylab("Count")
p<-p+scale_fill_manual(name="Survived/Death  ",values=c("red", "green"), 
                       labels=c("Death", "Survived"))
p<-p+labs(title=" Bar Plot Embarked -- Survived ")
p
```

```{r}
#There are two missing values 
#Assign U to these values 
RawData$Embarked<-as.character(RawData$Embarked)

if (sum(RawData$Embarked=="")>0)
  RawData[RawData$Embarked=="",]$Embarked<-"U"

RawData$Embarked<-as.factor(RawData$Embarked)


Rawtrain$Embarked<-RawData[1:nrow(Rawtrain),]$Embarked
test.index<-(nrow(Rawtrain)+1):(nrow(Rawtrain)+nrow(Rawtest))
Rawtest$Embarked<-RawData[test.index,]$Embarked

```

## Cabin
The cabin data  has a high percentage of missing data 
First, let's split the Cabin to the character and digits.
Some of the cabin cells include more than one cabin, 
but they are adjacent
We will use only the first one

```{r}
RawData<-RawData%>%
  mutate(Cabin_Charcter = str_extract(Cabin,"[A-Za-z][0-9]"))

RawData$Cabin_Charcter<-str_extract(RawData$Cabin_Charcter,"^[A-Za-z]")
#Mark all missing cabin character as U 
RawData[is.na(RawData$Cabin_Charcter),]$Cabin_Charcter<-"U"

#Convert to Factor 
RawData$Cabin_Charcter<-as.factor(RawData$Cabin_Charcter)

#Copy the Cabin Character to the train and test sets 
Rawtrain[,"Cabin_Charcter"]<-RawData[1:nrow(Rawtrain),"Cabin_Charcter"]
test.index<-(nrow(Rawtrain)+1):(nrow(Rawtrain)+nrow(Rawtest))
Rawtest[,"Cabin_Charcter"]<-RawData[test.index,]$Cabin_Charcter 

  
  
```

Lets see the Survivle/Death Versus the Cabin location 

```{r}
p<-ggplot(subset(Rawtrain,is.na(Cabin_Charcter)==FALSE),
          aes(x=as.factor(Cabin_Charcter),
              group=as.factor(Survived),fill=as.factor(Survived)))+
  geom_bar( position = "dodge")
p<-p+labs(title=" Bar Plot of Cabin  Vs. Survived ")
p<-p+xlab("Cabin ") + ylab("Count")
p<-p+scale_fill_manual("legend",
                       labels = c("Dead", "Survived"), values = c("red","green"))
p
```


## Normalize (Age, and Ticket Number)

Some of the Machine learning algorithms can leverage
normalize values (for the continuous observations)
We will create normlize colomns for 
1. Fare
2. Ticket Number
3. The various Age options (Mean,Median and RV)
```{r}
Rawtrain<-Rawtrain%>%
  mutate(Fare_Nor=normalize(Fare))

Rawtest<-Rawtest%>%
  mutate(Fare_Nor=normalize(Fare))

Rawtrain<-Rawtrain%>%
  mutate(TicketNumbers_Nor=normalize(TicketNumbers))

Rawtest<-Rawtest%>%
  mutate(TicketNumbers_Nor=normalize(TicketNumbers))

Rawtrain<-Rawtrain%>%
  mutate(AgeMean_Nor=normalize(AgeMean))

Rawtrain<-Rawtrain%>%
  mutate(AgeMedian_Nor=normalize(AgeMedian))

Rawtrain<-Rawtrain%>%
  mutate(AgeNormal_Nor=normalize(AgeNormal))

Rawtest<-Rawtest%>%
  mutate(AgeMean_Nor=normalize(AgeMean))

Rawtest<-Rawtest%>%
  mutate(AgeMedian_Nor=normalize(AgeMedian))

Rawtest<-Rawtest%>%
  mutate(AgeNormal_Nor=normalize(AgeNormal))


Rawtrain<-Rawtrain%>%
  mutate(GroupNo_Nor=normalize(GroupNo))

Rawtest<-Rawtest%>%
  mutate(GroupNo_Nor=normalize(GroupNo))

```

Convert Survived to a factor variable 
```{r}
Rawtrain$Survived<-as.factor(Rawtrain$Survived)
```


## Dummy variables 
Some models can not handle factor variables with more than 3 levels 
Creating dummy variable

```{r}
#Create  dummies variables for items with more than two options 

RawData$Pclass<-as.factor(RawData$Pclass)
RawData$Embarked<-as.factor(RawData$Embarked)
RawData$Title<-as.factor(RawData$Title)


Raw_Dummy<-dummy_cols(RawData,select_columns = c("Pclass","Title","Embarked","Cabin_Charcter","TicketChar"),remove_first_dummy = TRUE)
Raw_Dummy<-Raw_Dummy[,18:ncol(Raw_Dummy)]



#Copy the Cabin Character to the train and test sets 
test.index<-(nrow(Rawtrain)+1):(nrow(Rawtrain)+nrow(Rawtest))
Train_Dummy<-Raw_Dummy[-test.index,]
Test_Dummy<-Raw_Dummy[test.index,]


```



# Models

##Logoistic Regression 

###First Models is basic Logistic Regression 
These basic models scored ~~ 0.784-0.789

```{r}
train1<-dplyr::select(Rawtrain,Survived,Pclass,Sex,AgeMean,Fare,Embarked,Title,GroupNo,
               TicketChar,TicketNumbers,Cabin_Charcter,TicketNumbers_Nor,AgeNormal_Nor,
               AgeMedian_Nor,Fare_Nor,TicketNumbers_Nor,GroupNo_Nor,AgeMean_Nor)

test1<-dplyr::select(Rawtest,Pclass,Sex,AgeMean,Fare,Embarked,Title,GroupNo,
               TicketChar,TicketNumbers,Cabin_Charcter,TicketNumbers_Nor,AgeNormal_Nor,
               AgeMedian_Nor,Fare_Nor,TicketNumbers_Nor,GroupNo_Nor,AgeMean_Nor)


```




```{r}

#Split Data to train and validiation 
set.seed(1254)
train.index<-sample(1:nrow(train1),0.7*nrow(train1))
xtrain<-train1[train.index,]
valid<-train1[-train.index,]

train_control <- trainControl(method = "cv", number = 10)
set.seed(12345)
#train the model on training set
model.lg1 <- train(Survived ~ Sex+Fare+GroupNo+AgeMean_Nor+Cabin_Charcter+Pclass+Embarked+Title,
               data = xtrain,
                method = "glm",
               trControl =  train_control,
               family = binomial(link = "logit"))



# print cv scores
summary(model.lg1)
model.lg1

ypredict<-predict(model.lg1,newdata=valid)
confusionMatrix(ypredict,valid$Survived)

#Predict and write to file 
#res<-predict(model.lg1,newdata = test1)
#res<-data.frame(res)
#colnames(res)<-c("Survived")
#outcome<-cbind(Rawtest$PassengerId,res)
#colnames(outcome)<-c("PassengerId","Survived")


#write.csv(outcome,"out.csv",row.names=FALSE)


```

This submission got 0.78947



## Logistic regression with interaction terms

```{r}

#Split Data to train and validiation 
set.seed(1254)
train.index<-sample(1:nrow(train1),0.7*nrow(train1))
xtrain<-train1[train.index,]
valid<-train1[-train.index,]

train_control <- trainControl(method = "cv", number = 10)
set.seed(12345)
#train the model on training set
model.lg2 <- train(Survived ~ Sex+Fare+GroupNo+AgeMean_Nor+Cabin_Charcter+Pclass+Embarked+Title+Sex*AgeMean_Nor+Title*AgeMean_Nor,
               data = xtrain,
                method = "glm",
               trControl =  train_control,
               family = binomial(link = "logit"))



# print cv scores
summary(model.lg2)
model.lg2

ypredict<-predict(model.lg2,newdata=valid)
confusionMatrix(ypredict,valid$Survived)

#Predict and write to file 
#res<-predict(model.lg1,newdata = test1)
#res<-data.frame(res)
#colnames(res)<-c("Survived")
#outcome<-cbind(Rawtest$PassengerId,res)
#colnames(outcome)<-c("PassengerId","Survived")


#write.csv(outcome,"out.csv",row.names=FALSE)


```



## Lasso on Logitic regression 

```{r}
set.seed(12312)
x.train <- model.matrix(Survived ~Sex+Fare_Nor+GroupNo_Nor+AgeMean_Nor+Cabin_Charcter+Pclass+Embarked+Title, xtrain)

 y<- ifelse(xtrain$Survived == 1, 1, 0)
cv.lasso <- cv.glmnet(x.train, y, alpha = 1, family = "binomial",nfolds = 3)
model.Lasso <- glmnet(x.train, y, alpha = 1, family = "binomial",
                lambda = cv.lasso$lambda.min)




x.test <- model.matrix(Survived ~Sex+Fare_Nor+GroupNo_Nor+AgeMean_Nor+Cabin_Charcter+Pclass+Embarked+Title, valid)
probabilities <- model.Lasso %>% predict(newx = x.test)
res <- ifelse(probabilities > 0.5, 1, 0)
res<-as.factor(res)
confusionMatrix(res,valid$Survived)



```

This submission got 0.77990



## Ridge on Logitic regression 

```{r}
set.seed(12312)
x.train <- model.matrix(Survived ~Sex+Fare_Nor+GroupNo_Nor+AgeMean_Nor+Cabin_Charcter+Pclass+Embarked+Title, xtrain)
 y<- ifelse(xtrain$Survived == 1, 1, 0)

cv.Ridge <- cv.glmnet(x.train, y, alpha = 0, family = "binomial")
model.ridge <- glmnet(x.train, y, alpha = 0, family = "binomial",
                lambda = cv.Ridge$lambda.min)

x.test <- model.matrix(Survived ~Sex+Fare_Nor+GroupNo_Nor+AgeMean_Nor+Cabin_Charcter+Pclass+Embarked+Title, valid)
probabilities <- cv.Ridge %>% predict(newx = x.test)
res <- ifelse(probabilities > 0.5, 1, 0)
res<-as.factor(res)
confusionMatrix(res,valid$Survived)


```

This submission got
 0.77511
 



## Random Forest 
```{r}
#Split Data to train and validiation 
set.seed(1254)
train.index<-sample(1:nrow(train1),0.7*nrow(train1))
xtrain<-train1[train.index,]
valid<-train1[-train.index,]


#Fit Random Forest Model
rf = randomForest(as.factor(Survived) ~Sex+Fare+GroupNo+AgeMean+Cabin_Charcter+Pclass+Embarked+Title+TicketChar+TicketNumbers, #
                   ntree = 400,nodesize =5,mtry=22,
                   data = xtrain)
plot(rf)  


var.imp = data.frame(importance(rf,  
                                 type=2))
# make row names as columns
var.imp$Variables = row.names(var.imp)  
print(var.imp[order(var.imp$MeanDecreaseGini,decreasing = T),])

#predict
res<-predict(rf , valid)


confusionMatrix(data = res,  
                reference = valid$Survived)

```

### Random forest with dummies variables 

```{r}
trainOnlyDummies<-dplyr::select(Rawtrain,Survived,Sex,AgeMean,Fare,GroupNo,
               TicketNumbers)
testOnlyDummies<-dplyr::select(Rawtest,Sex,AgeMean,Fare,GroupNo,
               TicketNumbers)

trainOnlyDummies<-cbind(trainOnlyDummies,Train_Dummy)
testOnlyDummies<-cbind(testOnlyDummies,Test_Dummy)


set.seed(1254)
train.index<-sample(1:nrow(trainOnlyDummies),.7*nrow(trainOnlyDummies))
xtrain<-trainOnlyDummies[train.index,]
valid<-trainOnlyDummies[-train.index,]

set.seed(1254)
#Fit Random Forest Model
rf = randomForest(as.factor(Survived) ~., #
                   ntree = 1500,nodesize =5,mtry=22,
                   data = xtrain)
plot(rf)  


var.imp = data.frame(importance(rf,  
                                 type=2))
# make row names as columns
var.imp$Variables = row.names(var.imp)  
print(var.imp[order(var.imp$MeanDecreaseGini,decreasing = T),])

#predict
res<-predict(rf , valid)


confusionMatrix(data = res,  
                reference = valid$Survived)

```



###Tunning paramters

```{r}
control <- trainControl(method="repeatedcv", number=10, repeats=3)
seed <- 7
metric <- "Accuracy"
set.seed(seed)
x<-xtrain
mtry <- sqrt(ncol(x))
tunegrid <- expand.grid(.mtry=mtry)
rf_default <- train(as.factor(Survived)~., data=x, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
print(rf_default)
```

#### Tune Using Caret
The caret package in R provides an excellent facility to tune machine learning algorithm parameters.

As such, only mtry parameter is available in caret for tuning. The reason is its effect on the final accuracy and that it must be found empirically for a dataset.

The ntree parameter is different in that it can be as large as you like, and continues to increases the accuracy up to some point. It is less difficult or critical to tune and could be limited more by compute time available more than anything.


#### Random  and Grid Search for mtry



trainOnlyDummies<-dplyr::select(Rawtrain,Survived,Sex,AgeMean,Fare,GroupNo,
               TicketNumbers)
testOnlyDummies<-dplyr::select(Rawtest,Sex,AgeMean,Fare,GroupNo,
               TicketNumbers)

trainOnlyDummies<-cbind(trainOnlyDummies,Train_Dummy)
testOnlyDummies<-cbind(testOnlyDummies,Test_Dummy)


set.seed(1254)
train.index<-sample(1:nrow(trainOnlyDummies),0.7*nrow(trainOnlyDummies))
xtrain<-trainOnlyDummies[train.index,]
valid<-trainOnlyDummies[-train.index,]


# Random Search



# Manual Search
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(.mtry=c(sqrt(ncol(x))))
modellist <- list()
for (ntree in c(1000, 1500, 2000, 2500)) {
	set.seed(seed)
	fit <- train(Class~., data=dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control, ntree=ntree)
	key <- toString(ntree)
	modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
dotplot(results)




control <- trainControl(method="repeatedcv", number=10, repeats=3, search="random")
set.seed(seed)
mtry <- sqrt(ncol(x))
rf_random <- train(as.factor(Survived)~., data=x, method="rf", metric=metric, tuneLength=15, trControl=control)
print(rf_random)
plot(rf_random)


#Grid Search 
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(seed)
tunegrid <- expand.grid(.mtry=c(1:25))
rf_gridsearch <- train(as.factor(Survived)~., data=x, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
print(rf_gridsearch)
plot(rf_gridsearch)







### Extend Caret search for best number of trees



x <- xtrain[,c(1:ncol(xtrain))]
y <- xtrain[,1]

customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes



# train model
control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(1:25), .ntree=c(1000, 1500, 2000, 2500))
set.seed(seed)
custom <- train(as.factor(Survived)~., data=xtrain, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
summary(custom)
plot(custom)


